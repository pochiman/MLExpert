# 2 - Prerequisites
We know, we know, you're eager to get out there and build some cool sentient systems. However, 
like all fun things in life, machine learning is preceded by a good amount of human learning.

In that spirit, let's kick things off by reviewing some important prerequisites you'll need on 
your journey to machine mastery.

# Key Terms

# [Features]
A set of quantities or properties describing an observation. They can be binary like "day" 
and "night"; categorical like "morning", "afternoon", and "evening"; continuous like 3.141; 
or ordinal like "threatened", :endangered", "extinct", where the categories can be ordered.

# [Labels]
Usually paired with a set of features for use in supervised learning. Can be discrete or 
continuous.

# [Examples]
Pairs of features and labels.

# [Dimensions]
Here, the number of features associated with a particular example.

# [Vector]
Here, a feature vector, which is a list of features representing a particular example.

# [Matrix]
An array of values, usually consisting of multiple rows and columns.

# [Matrix_Transpose]
An operator that flips a matrix over its diagonal.

# [Polynomial]
A function with more than one variable/coefficient pair.

# [Derivative]
Indicates how much the output of a function will change with respect to a change in its 
input.

# [Probability]
How likely something is to occur. This can be independent, such as the roll of the dice, 
or conditional, such as drawing two cards subsequently out of a deck without replacement.

# [Probability_Distribution]
A function that takes in an outcome and outputs the probability of that particular outcome 
occurring.

# [Gaussian_Distribution]
A very common type of probability distribution which fits many real world observations; 
also called a normal distribution.

# [Uniform_Distribution]
A probability distribution in which each outcome is equally likely; for example, rolling 
a normal six-sided die.
